{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the AACT clinical trials database from local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import pandas.io.sql as pd_sql\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input AACT connection arguments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Refactor the login code. Is there a better way to get a text file or other file in with the login credentials?  Can I make the entire connection process a function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "login = pd.read_csv('login.csv', header=None)\n",
    "user = login.iloc[0,0]\n",
    "password = login.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_args = {'host': 'aact-db.ctti-clinicaltrials.org', \n",
    "                   'user': user, \n",
    "                   'password': password, \n",
    "                   'dbname': 'aact',\n",
    "                   'port': 5432}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AACT database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = pg.connect(**connection_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute queries for eligibility criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eligibility criteria: inclusion and exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM eligibilities LIMIT 1;\"\n",
    "\n",
    "data = pd_sql.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_load = pd.read_pickle(\"test_data.pkl\")\n",
    "# test_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary for each study to load into MongoDB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a single record and create an empty dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id = data.nct_id[1]\n",
    "eligibility = data.criteria[1]\n",
    "print(eligibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = {}\n",
    "document['study_id'] = study_id\n",
    "document['minimum_age'] = data.minimum_age[0]\n",
    "document['maximum_age'] = data.maximum_age[0]\n",
    "document['gender'] = data.gender[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split inclusion and exclusion criteria "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add a test to see if Inclusion and Exclusion criteria are included in every study - some studies lack exclusion criteria and only have inclusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inclusion, exclusion = eligibility.split('Exclusion Criteria:')\n",
    "inclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find inclusion criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '-\\s\\s(.+)\\n\\n'\n",
    "inclusion_criteria = re.findall(regex, inclusion)\n",
    "document['inclusion_criteria'] = inclusion_criteria\n",
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find exclusion criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '-\\s\\s(.+)\\n\\n'\n",
    "exclusion_criteria = re.findall(regex, exclusion)\n",
    "document['exclusion_criteria'] = exclusion_criteria\n",
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create a dictionary record from a SQL query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document(record):\n",
    "    document = {}\n",
    "    document['study_id'] = record.nct_id[0]\n",
    "    document['minimum_age'] = record.minimum_age[0]\n",
    "    document['maximum_age'] = record.maximum_age[0]\n",
    "    document['gender'] = record.gender[0]\n",
    "    \n",
    "    # need to test if there is 'Exclusion Criteria:' in the dataset\n",
    "    eligibility = record.criteria[0]\n",
    "    eligibility = eligibility.replace('\\n             ', ' ') \n",
    "    inclusion, exclusion = eligibility.split('Exclusion Criteria:')\n",
    "    regex = '-\\s\\s(.+)\\n\\n'\n",
    "    clean_inclusion = re.findall(regex, inclusion)\n",
    "    clean_exclusion = re.findall(regex, exclusion)\n",
    "    document['inclusion_criteria'] = clean_inclusion\n",
    "    document['exclusion_criteria'] = clean_exclusion\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a cursor and iterate through queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update record cleaner function for SQL cursor queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SQL cursor returns a tuple, so we must update the indexing for tuples, instead of dataframes with labeled columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_record(record):\n",
    "    \n",
    "    \"\"\"Takes an AACT database read from an SQL cursor and produces a dictionary. \n",
    "    Removes new lines and extra spaces from eligibility criteria. \n",
    "    Returns a dictionary in document form to be sent to mongodb.\"\"\"\n",
    "    \n",
    "    document = {}\n",
    "    document['study_id'] = record[1]\n",
    "    document['minimum_age'] = record[4]\n",
    "    document['maximum_age'] = record[5]\n",
    "    document['gender'] = record[3]\n",
    "    \n",
    "    eligibility = record[8]\n",
    "    eligibility = eligibility.replace('\\n             ', ' ') \n",
    "    \n",
    "    # need to test if there is 'Exclusion Criteria:' in the dataset\n",
    "    # if there isn't Exclusion Criteria, don't have to split the eligibility\n",
    "    \n",
    "    inclusion, exclusion = eligibility.split('Exclusion Criteria:')\n",
    "    regex = '-\\s\\s(.+)\\n\\n'\n",
    "    clean_inclusion = re.findall(regex, inclusion)\n",
    "    clean_exclusion = re.findall(regex, exclusion)\n",
    "    document['inclusion_criteria'] = clean_inclusion\n",
    "    document['exclusion_criteria'] = clean_exclusion\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_mongodb(document, database, collection):\n",
    "    \n",
    "    \"\"\"Takes a dictionary in document form and sends it to the specified database\n",
    "    and collection in mongodb. document is the document to enter into the database. \n",
    "    database and collection are specified as strings.\"\"\"\n",
    "    \n",
    "    # Create an error message if there is no database or collection specified \n",
    "    \n",
    "    client = MongoClient() # Connect to/close mongo outside function?\n",
    "    db = client[database] # can I use variable like this? Can test that...\n",
    "    collection = db[collection]  \n",
    "    collection.insert_one(document)\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to read in the login credentials:\n",
    "connection_args = json.load(open(\"login.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a login.txt file with the database and login credentials, adding in your specific username and password:\n",
    "\n",
    "{\"host\": \"aact-db.ctti-clinicaltrials.org\", \"user\": \"username\", \"password\": \"password\", \"dbname\": \"aact\", \"port\": 5432}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login = pd.read_csv('login.csv', header=None)\n",
    "user = login.iloc[0,0]\n",
    "password = login.iloc[0,1]\n",
    "\n",
    "connection_args = {'host': 'aact-db.ctti-clinicaltrials.org', \n",
    "                   'user': user, \n",
    "                   'password': password, \n",
    "                   'dbname': 'aact',\n",
    "                   'port': 5432}\n",
    "\n",
    "connection = pg.connect(**connection_args)\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_mongo(query, login, database, collection):\n",
    "    \n",
    "    \"\"\"SQL to MongoDB pipeline. Retrieves single SQL record from a cursor, \n",
    "    converts it into a dictionary, and inputs that to MongoDB.\n",
    "    query is a SQL query. login is a text file with the login parameters. \n",
    "    database and collections are strings of MongoDB locations. \n",
    "    login is the login specifications for the SQL database.\"\"\"\n",
    "    \n",
    "    connection_args = json.load(open(login))\n",
    "    connection = pg.connect(**connection_args)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query) # open the database connection within the function as well? \n",
    "    \n",
    "    for result in cursor:\n",
    "        document = clean_record(result)\n",
    "        send_to_mongodb(document, database, collection)\n",
    "        \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM eligibilities LIMIT 3;\"\n",
    "\n",
    "sql_to_mongo(query, 'login.txt', 'test_database', 'trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close connection to AACT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
